import pandas as pd
import numpy as np
import os
import glob

# --- Cáº¤U HÃŒNH ---
INPUT_ROOT_DIR = r"D:\DACN\dataset\raw\CICEVSE2024_Dataset\Network Traffic"
OUTPUT_PATH = r"D:\DACN\dataset\processed\drift_test_data_full1.2.csv"

# Äáº·t sá»‘ lÆ°á»£ng máº«u tá»‘i Ä‘a muá»‘n láº¥y. 
# Äáº·t None náº¿u muá»‘n láº¥y háº¿t (cáº©n tháº­n RAM), hoáº·c Ä‘áº·t sá»‘ cá»¥ thá»ƒ (vÃ­ dá»¥: 2000000)
MAX_SAMPLES = 2000000 

def process_and_merge_data():
    print(f"ğŸš€ [START] QuÃ©t dá»¯ liá»‡u tá»«: {INPUT_ROOT_DIR}")
    
    all_files = glob.glob(os.path.join(INPUT_ROOT_DIR, "**/*.csv"), recursive=True)
    if not all_files:
        print("âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file .csv nÃ o!")
        return

    print(f"--> TÃ¬m tháº¥y: {len(all_files)} file CSV.")
    
    processed_dfs = []
    total_rows = 0
    
    # Danh sÃ¡ch 8 cá»™t báº¯t buá»™c
    required_cols = [
        "Flow Duration", "Total Fwd Packets", "Total Bwd Packets", 
        "Flow Packets/s", "Flow IAT Mean", "Fwd Header Length", 
        "Packet Length Mean", "ACK Flag Count"
    ]

    for file_path in all_files:
        # Kiá»ƒm tra giá»›i háº¡n máº«u
        if MAX_SAMPLES is not None and total_rows >= MAX_SAMPLES:
            print(f"ğŸ›‘ ÄÃ£ Ä‘áº¡t giá»›i háº¡n {MAX_SAMPLES} máº«u. Dá»«ng Ä‘á»c.")
            break

        try:
            print(f"â³ Äang Ä‘á»c: {os.path.basename(file_path)}...", end="\r") # In Ä‘Ã¨ dÃ²ng Ä‘á»ƒ gá»n console
            df = pd.read_csv(file_path)

            # 1. Rename
            rename_dict = {
                'bidirectional_duration_ms': 'Flow Duration',
                'src2dst_packets': 'Total Fwd Packets',
                'dst2src_packets': 'Total Bwd Packets',
                'bidirectional_mean_piat_ms': 'Flow IAT Mean',
                'bidirectional_mean_ps': 'Packet Length Mean',
                'bidirectional_ack_packets': 'ACK Flag Count'
            }
            df = df.rename(columns=rename_dict)

            # 2. Kiá»ƒm tra sÆ¡ bá»™
            if 'Flow Duration' not in df.columns:
                print(f"\n   âš ï¸ Bá» qua {os.path.basename(file_path)}: KhÃ´ng Ä‘Ãºng Ä‘á»‹nh dáº¡ng.")
                continue

            # 3. TÃ­nh toÃ¡n & Xá»­ lÃ½ Ä‘Æ¡n vá»‹
            df['Flow Duration'] = df['Flow Duration'] * 1000  # ms -> us
            df['Flow IAT Mean'] = df['Flow IAT Mean'] * 1000  # ms -> us
            
            total_packets = df['Total Fwd Packets'] + df['Total Bwd Packets']
            duration_seconds = df['Flow Duration'] / 1e6
            df['Flow Packets/s'] = total_packets / duration_seconds.replace(0, 1)

            # 4. Táº O DRIFT (QUAN TRá»ŒNG)
            df['Fwd Header Length'] = 0 

            # 5. Lá»c cá»™t vÃ  lÃ m sáº¡ch
            missing = [c for c in required_cols if c not in df.columns]
            if missing:
                print(f"\n   âš ï¸ Bá» qua {os.path.basename(file_path)}: Thiáº¿u cá»™t {missing}")
                continue

            temp_df = df[required_cols].copy()
            temp_df = temp_df.replace([np.inf, -np.inf], np.nan).fillna(0)
            
            processed_dfs.append(temp_df)
            total_rows += len(temp_df)
            
        except Exception as e:
            print(f"\n   âŒ Lá»—i file {os.path.basename(file_path)}: {e}")

    if processed_dfs:
        print(f"\n\nğŸ”„ Äang gá»™p {len(processed_dfs)} DataFrames...")
        final_df = pd.concat(processed_dfs, ignore_index=True)
        
        # Cáº¯t chÃ­nh xÃ¡c sá»‘ lÆ°á»£ng máº«u láº§n cuá»‘i náº¿u lá»¡ bá»‹ thá»«a do file cuá»‘i cÃ¹ng
        if MAX_SAMPLES is not None and len(final_df) > MAX_SAMPLES:
            final_df = final_df.iloc[:MAX_SAMPLES]
            
        os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)
        final_df.to_csv(OUTPUT_PATH, index=False)
        print(f"ğŸ‰ XONG! File lÆ°u táº¡i: {OUTPUT_PATH}")
        print(f"ğŸ“Š KÃ­ch thÆ°á»›c cuá»‘i cÃ¹ng: {final_df.shape}")
    else:
        print("âŒ KhÃ´ng táº¡o Ä‘Æ°á»£c dá»¯ liá»‡u nÃ o.")

if __name__ == "__main__":
    process_and_merge_data()